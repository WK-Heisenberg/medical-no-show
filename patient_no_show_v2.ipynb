{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Customer No-Show Prediction with XGBoost\n",
    "_**Using Gradient Boosted Trees to predict Medical Appointment No-Shows**_\n",
    "\n",
    "---\n",
    "\n",
    "---\n",
    "\n",
    "## Contents\n",
    "\n",
    "1. [Background](#Background)\n",
    "1. [Setup](#Setup)\n",
    "1. [Data](#Data)\n",
    "1. [Train](#Train)\n",
    "1. [Host](#Host)\n",
    "  1. [Evaluate](#Evaluate)\n",
    "  1. [Relative cost of errors](#Relative-cost-of-errors)\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "## Background\n",
    "\n",
    "_This notebook has been adapted from an [AWS blog post](https://aws.amazon.com/blogs/ai/predicting-customer-churn-with-amazon-machine-learning/)_\n",
    "\n",
    "---\n",
    "\n",
    "## Setup\n",
    "\n",
    "_This notebook was created and tested on an ml.m4.xlarge notebook instance._\n",
    "\n",
    "Let's start by specifying:\n",
    "\n",
    "- The S3 bucket and source or presigned url to the S3 bucket containg the data that you want to use for training and model data.  This should be within the same region as the Notebook Instance, training, and hosting.\n",
    "- The IAM role arn used to give training and hosting access to your data. See the documentation for how to create these.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll import the Python libraries we'll need for the remainder of the exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import re\n",
    "import time\n",
    "import sagemaker\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import io\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import json\n",
    "from IPython.display import display\n",
    "from time import strftime, gmtime\n",
    "from sagemaker import get_execution_role"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "isConfigCell": true,
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Set session \n",
    "sm = sagemaker.Session()\n",
    "\n",
    "# Set default bucket for model artifacts and data channels\n",
    "bucket = sm.default_bucket()\n",
    "\n",
    "# SageMaker Role\n",
    "role = get_execution_role()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Data\n",
    "\n",
    "The Kaggle dataset comprised 110k appointments records from public healthcare institutions in a Brazilian city. The appointments occurred across a 6-week period in 2016.\n",
    "\n",
    "110.527 medical appointments its 14 associated variables (characteristics)\n",
    "\n",
    "## Data Dictionary\n",
    "\n",
    "01 - PatientId\n",
    "Identification of a patient\n",
    "\n",
    "02 - AppointmentID\n",
    "Identification of each appointment\n",
    "\n",
    "03 - Gender\n",
    "Male or Female . Female is the greater proportion, woman takes way more care of they health in comparison to man.\n",
    "\n",
    "04 - DataMarcacaoConsulta\n",
    "The day of the actuall appointment, when they have to visit the doctor.\n",
    "\n",
    "05 - DataAgendamento\n",
    "The day someone called or registered the appointment, this is before appointment of course.\n",
    "\n",
    "06 - Age\n",
    "How old is the patient.\n",
    "\n",
    "07 - Neighbourhood\n",
    "Where the appointment takes place.\n",
    "\n",
    "08 - Scholarship\n",
    "True of False . Observation, this is a broad topic, consider reading this article https://en.wikipedia.org/wiki/Bolsa_Fam%C3%ADlia\n",
    "\n",
    "09 - Hipertension\n",
    "True or False\n",
    "\n",
    "10 - Diabetes\n",
    "True or False\n",
    "\n",
    "11 - Alcoholism\n",
    "True or False\n",
    "\n",
    "12 - Handcap\n",
    "True or False\n",
    "\n",
    "13 - SMS_received\n",
    "1 or more messages sent to the patient.\n",
    "\n",
    "14 - No_show\n",
    " True or False.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory data analysis & feature engineering "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data into a Pandas Data Frame and inspect the data\n",
    "df = pd.read_csv('no-show-data.csv')\n",
    "df.head(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correct misspelling of column names\n",
    "df.rename(columns = {'ApointmentData':'AppointmentData',\n",
    "                         'Alcoolism': 'Alchoholism',\n",
    "                         'Hipertension': 'Hypertension',\n",
    "                         'Handcap': 'Handicap',\n",
    "                         'No-show': 'No_show'}, inplace = True)\n",
    "\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 100)\n",
    "df.head(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for any missing data\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Frequency tables for some of the categorical feature(s)\n",
    "# for column in df.select_dtypes(include=['object']).columns:\n",
    "for column in df[[ 'Scholarship','Gender','No_show', 'Diabetes', 'Hypertension','Alcoholism','Handicap']]:       \n",
    "    display(pd.crosstab(index=df[column], columns='% observations', normalize='columns'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histograms for each feature\n",
    "display(df.describe())\n",
    "%matplotlib inline\n",
    "hist = df.hist(bins=40, sharey=True, figsize=(20, 8))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df.corr())\n",
    "pd.plotting.scatter_matrix(df, figsize=(15, 15))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Relationship on 'Scholarship', 'Hypertension','Diabetes', 'Alcoholism', 'Handicap', 'SMS_received' with No_show make proportions for each elements to find the relationships\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Relationship on 'Scholarship', 'Hypertension','Diabetes', 'Alcoholism', 'Handicap', 'SMS_received' with No_show - Plot proportions for each elements to find the relationships\n",
    "df_new = df.groupby('No_show')['Scholarship', 'Hypertension',\\\n",
    "                       'Diabetes', 'Alcoholism', 'Handicap', 'SMS_received'].sum()\n",
    "noshow_6r = df_new.query(\"No_show == 'Yes'\")\n",
    "noshow_total = df['No_show'].value_counts()[1]\n",
    "prop_6r = noshow_6r / noshow_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style('darkgrid')\n",
    "prop_6r.plot(kind='bar',figsize=(16,8),\\\n",
    "            title='Relationship on 6 factors with No-Show')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Wrangling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cast to int64\n",
    "df['PatientId'] = df['PatientId'].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make PatientID the index column and No_show the first column in the dataframe (SageMaker's XGBoost expects the target variable to be in the first column when using csv)\n",
    "df.set_index('PatientId', inplace = True)\n",
    "df = df[ ['No_show'] + [ col for col in df.columns if col != 'No_show' ] ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check changes applied\n",
    "df.head(n=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the histograms abobe we can see immediately that 'Age\" has negative values and needs to be further evaluated\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Age'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of 'Age'\n",
    "plt.figure();\n",
    "age_hist = df['Age'].plot.hist(bins=10)\n",
    "age_hist.set_xlabel(\"Age\")\n",
    "age_hist.set_ylabel(\"Patients\")\n",
    "age_hist.set_title('Distribution of Age')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only keep records of patients where they are between 0-99 in age to remove outliers.\n",
    "df = df[(df.Age >= 0) & (df.Age <= 99)]\n",
    "\n",
    "min_age = df['Age'].min()\n",
    "max_age = df['Age'].max()\n",
    "print (\"Age now spans values from: {} to {}.\".format(min_age, max_age))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next let's look at the relationship between each of the features and our target variable\n",
    "for column in df.select_dtypes(include=['object']).columns:\n",
    "    if column != 'No_show':\n",
    "        display(pd.crosstab(index=df[column], columns=df['No_show'], normalize='columns'))\n",
    "\n",
    "for column in df.select_dtypes(exclude=['object']).columns:\n",
    "    print(column)\n",
    "    hist = df[[column, 'No_show']].hist(by='No_show', bins=30)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Amazon SageMaker XGBoost can train on data in either a CSV or LibSVM format.  For this example, we'll stick with CSV.  It should:\n",
    "- Have the predictor variable in the first column\n",
    "- Not have a header row\n",
    "\n",
    "But first, let's convert our categorical features into numeric features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### This feature is suppose to be true/false \n",
    "df['Handicap'].replace([2,3,4],1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace 'M' and 'F' with 1 and 0 for 'Gender' and 'Yes' and 'No'\n",
    "# with 1 and 0 for 'No_show'\n",
    "df['Gender'] = df['Gender'].map({'M':1, \n",
    "                                 'F':0}\n",
    "                               )\n",
    "df['No_show'] = df['No_show'].map({'Yes':1, \n",
    "                                   'No':0}\n",
    "                                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforming ScheduledDay and AppointmentDay into datetime objects and stripping hours, minutes and seconds.\n",
    "dt_scheduledDay =  pd.to_datetime(df.ScheduledDay).dt.date\n",
    "dt_appointmentDay = pd.to_datetime(df.AppointmentDay).dt.date\n",
    "\n",
    "# Storing \"delta_days\" to df as a new feature\n",
    "df['Days_delta'] = (dt_appointmentDay - dt_scheduledDay).dt.days\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing AppointmentDay to a datetime pandas object to create a new dayofweek engineered feature\n",
    "df['AppointmentDay'] = pd.to_datetime(df['AppointmentDay'])\n",
    "df['No_show_weekday'] = df['AppointmentDay'].dt.dayofweek\n",
    "#df['No_show_weekday'] = df[['No_show', 'No_show_weekday']].groupby('No_show_weekday').mean()\n",
    "#df['No_show_weekday'].sample(5)\n",
    "sns.barplot(y='No_show', x='No_show_weekday', data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# days_delta contains impossible values such as -6 and -1 \n",
    "# which look like mistakes/outliers but require further investigation.\n",
    "\n",
    "days_hist = df['Days_delta'].plot.hist(bins=8)\n",
    "days_hist.set_xlabel(\"Days delta\")\n",
    "days_hist.set_xticks(range(0, 180, 10))\n",
    "days_hist.set_ylabel(\"Patients\")\n",
    "days_hist.set_title('Distribution of Days delta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# days_delta < 0 and > 90 are not on the histogram which indicates that they don't belong to a patient/few patients and therefore should be removed.\n",
    "df = df[(df.Days_delta >= 0) & (df.Days_delta <= 70)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating vars to hold categorical features for one hot encoding\n",
    "cat_features_for_encoding = ['Handicap', 'Neighbourhood']\n",
    "\n",
    "# Creating var for all numerical features in case we want to deep dive to identify\n",
    "# which age and what days delta are the most important in predicting \"No_show\" outcome\n",
    "num_features_for_encoding = ['Age', 'Days_delta']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-Hot encoding on categorical columns to prepare dataset for machine learning modelling.\n",
    "encoded_df = pd.get_dummies(df, columns=cat_features_for_encoding)\n",
    "print (\"New encoded dataframe has {} rows and {} features.\".format(encoded_df.shape[0], encoded_df.shape[1]))\n",
    "\n",
    "# Increasing the max column shown for this cell to 100\n",
    "pd.set_option(\"max_columns\", 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping columns that we have encoded\n",
    "features = encoded_df.drop(['ScheduledDay', 'AppointmentDay'], axis=1)\n",
    "features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_data = features\n",
    "train_data, validation_data, test_data = np.split(model_data.sample(frac=1, random_state=1729), [int(0.7 * len(model_data)), int(0.9 * len(model_data))])\n",
    "train_data.to_csv('train.csv', header=False, index=False)\n",
    "validation_data.to_csv('validation.csv', header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll upload these files to S3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boto3.Session().resource('s3').Bucket(bucket).Object(os.path.join('train/train.csv')).upload_file('train.csv')\n",
    "boto3.Session().resource('s3').Bucket(bucket).Object(os.path.join('validation/validation.csv')).upload_file('validation.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Training and HPO\n",
    "\n",
    "Moving onto training, first we'll need to specify the locations of the XGBoost algorithm containers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.amazon.amazon_estimator import get_image_uri\n",
    "# container = get_image_uri(boto3.Session().region_name, 'xgboost', repo_version='0.90-2')\n",
    "container = get_image_uri(boto3.Session().region_name, 'xgboost', repo_version='latest')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, because we're training with the CSV file format, we'll create `s3_input`s that our training function can use as a pointer to the files in S3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_input_train = sagemaker.s3_input(s3_data='s3://{}/train'.format(bucket), content_type='csv')\n",
    "s3_input_validation = sagemaker.s3_input(s3_data='s3://{}/validation/'.format(bucket), content_type='csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can specify a few parameters like what type of training instances we'd like to use and how many, as well as our XGBoost hyperparameters.  A few key hyperparameters are:\n",
    "- `max_depth` controls how deep each tree within the algorithm can be built.  Deeper trees can lead to better fit, but are more computationally expensive and can lead to overfitting.  There is typically some trade-off in model performance that needs to be explored between a large number of shallow trees and a smaller number of deeper trees.\n",
    "- `subsample` controls sampling of the training data.  This technique can help reduce overfitting, but setting it too low can also starve the model of data.\n",
    "- `num_round` controls the number of boosting rounds.  This is essentially the subsequent models that are trained using the residuals of previous iterations.  Again, more rounds should produce a better fit on the training data, but can be computationally expensive or lead to overfitting.\n",
    "- `eta` controls how aggressive each round of boosting is.  Larger values lead to more conservative boosting.\n",
    "- `gamma` controls how aggressively trees are grown.  Larger values lead to more conservative models.\n",
    "\n",
    "More detail on XGBoost's hyperparmeters can be found on their GitHub [page](https://docs.aws.amazon.com/sagemaker/latest/dg/xgboost-tuning.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.tuner import IntegerParameter, CategoricalParameter, ContinuousParameter, HyperparameterTuner\n",
    "\n",
    "sess = sagemaker.Session()\n",
    "xgb = sagemaker.estimator.Estimator(container,\n",
    "                                    role, \n",
    "                                    train_instance_count=1, \n",
    "                                    train_instance_type='ml.m4.xlarge',\n",
    "                                    output_path='s3://{}/output'.format(bucket),\n",
    "                                    sagemaker_session=sess)\n",
    "\n",
    "xgb.set_hyperparameters(eval_metric='auc',\n",
    "                        objective='binary:logistic',\n",
    "                        max_depth=7,\n",
    "                        alpha=0.01,\n",
    "                        eta=0.2,\n",
    "                        gamma=4,\n",
    "                        rate_drop=0.3,\n",
    "                        tweedie_variance_power=1.4,\n",
    "                        min_child_weight=5,\n",
    "                        subsample=0.8,\n",
    "                        silent=0,\n",
    "                        num_round=100)\n",
    "\n",
    "xgb.fit({'train': s3_input_train, 'validation': s3_input_validation}) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## HPO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Logarithmic scaling¶\n",
    "\n",
    "Let us compare the results with executing a job using logarithmic scaling.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting HPO Config Files (log)\n",
    "objective_metric_name = 'validation:auc'\n",
    "hyperparameter_ranges = {\n",
    "    'alpha': ContinuousParameter(0.01, 10, scaling_type=\"Logarithmic\"),\n",
    "    'lambda': ContinuousParameter(0.01, 10, scaling_type=\"Logarithmic\")\n",
    "}\n",
    "\n",
    "tuner_log = HyperparameterTuner(\n",
    "    xgb,\n",
    "    objective_metric_name,\n",
    "    hyperparameter_ranges,\n",
    "    max_jobs=40,\n",
    "    max_parallel_jobs=10,\n",
    "    strategy='Bayesian'\n",
    ")\n",
    "\n",
    "tuner_log.fit({'train': s3_input_train, 'validation': s3_input_validation}, include_cls_metadata=False, job_name=\"tuner-log\" + time.strftime('%Y-%m-%d-%H-%M-%S', time.localtime()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Linear scaling¶\n",
    "\n",
    "Let us compare the results with executing a job using linear scaling.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting HPO Config Files (linear)\n",
    "objective_metric_name = 'validation:auc'\n",
    "hyperparameter_ranges_linear = {\n",
    "    'alpha': ContinuousParameter(0.01, 10, scaling_type=\"Linear\"),\n",
    "    'lambda': ContinuousParameter(0.01, 10, scaling_type=\"Linear\")\n",
    "}\n",
    "tuner_linear = HyperparameterTuner(\n",
    "    xgb,\n",
    "    objective_metric_name,\n",
    "    hyperparameter_ranges_linear,\n",
    "    max_jobs=40,\n",
    "    max_parallel_jobs=10,\n",
    "    strategy='Bayesian'\n",
    ")\n",
    "\n",
    "tuner_linear.fit({'train': s3_input_train, 'validation': s3_input_validation}, include_cls_metadata=False, job_name=\"tuner-linear\" + time.strftime('%Y-%m-%d-%H-%M-%S', time.localtime()))\n",
    "tuner_linear.wait()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boto3.client('sagemaker').describe_hyper_parameter_tuning_job(HyperParameterTuningJobName=tuner_linear.latest_tuning_job.job_name)['HyperParameterTuningJobStatus']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boto3.client('sagemaker').describe_hyper_parameter_tuning_job(HyperParameterTuningJobName=tuner_log.latest_tuning_job.job_name)['HyperParameterTuningJobStatus']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Analyze tuning job results - after tuning job is completed\n",
    "\n",
    "Once the tuning jobs have completed, we can compare the distribution of the hyperparameter configurations chosen in the two cases.\n",
    "\n",
    "Please refer to \"HPO_Analyze_TuningJob_Results.ipynb\" to see more example code to analyze the tuning job results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check jobs have finished\n",
    "status_log = boto3.client('sagemaker').describe_hyper_parameter_tuning_job(\n",
    "    HyperParameterTuningJobName=tuner_log.latest_tuning_job.job_name)['HyperParameterTuningJobStatus']\n",
    "status_linear = boto3.client('sagemaker').describe_hyper_parameter_tuning_job(\n",
    "    HyperParameterTuningJobName=tuner_linear.latest_tuning_job.job_name)['HyperParameterTuningJobStatus']\n",
    "\n",
    "assert status_log == 'Completed', \"First must be completed, was {}\".format(status_log)\n",
    "assert status_linear == 'Completed', \"Second must be completed, was {}\".format(status_linear)\n",
    "\n",
    "df_log = sagemaker.HyperparameterTuningJobAnalytics(tuner_log.latest_tuning_job.job_name).dataframe()\n",
    "df_linear = sagemaker.HyperparameterTuningJobAnalytics(tuner_linear.latest_tuning_job.job_name).dataframe()\n",
    "df_log['scaling'] = 'log'\n",
    "df_linear['scaling'] = 'linear'\n",
    "df = pd.concat([df_log, df_linear], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.FacetGrid(df, col=\"scaling\", palette='viridis')\n",
    "g = g.map(plt.scatter, \"alpha\", \"lambda\", alpha=0.6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Host\n",
    "\n",
    "Now that we've trained the algorithm, let's create a model and deploy it to a hosted endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return name of the best training job for the latest \"log\" hyperparameter tuning job\n",
    "best_training_job = tuner_log.best_training_job()\n",
    "print(best_training_job)\n",
    "xgb_predictor = xgb.deploy(initial_instance_count = 1, instance_type = 'ml.m4.xlarge',model_name=best_training_job, endpoint_name=\"XGBoost-best-HPO-model-{}\".format(int(time.time())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate\n",
    "\n",
    "Now that we have a hosted endpoint running, we can make real-time predictions from our model very easily, simply by making an http POST request.  But first, we'll need to setup serializers for passing our `test_data` NumPy arrays to the model behind the endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_predictor.content_type = 'text/csv'\n",
    "xgb_predictor.serializer = sagemaker.predictor.csv_serializer\n",
    "xgb_predictor.deserializer = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For CSV inference, the algorithm assumes that CSV input does not have the label column \n",
    "test_data.drop(labels='No_show', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we'll use a simple function to:\n",
    "1. Loop over our test dataset\n",
    "1. Split it into mini-batches of rows \n",
    "1. Convert those mini-batchs to CSV string payloads\n",
    "1. Retrieve mini-batch predictions by invoking the XGBoost endpoint\n",
    "1. Collect predictions and convert from the CSV output our model provides into a NumPy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to chunk down test set into smaller increments\n",
    "\n",
    "def predict(data, model, rows=500):\n",
    "    split_array = np.array_split(data, int(data.shape[0] / float(rows) + 1))\n",
    "    predictions = ''\n",
    "    for array in split_array:\n",
    "        predictions = ','.join([predictions, model.predict(array).decode('utf-8')])\n",
    "\n",
    "    return np.fromstring(predictions[1:], sep=',')\n",
    "\n",
    "## Generate predictions on the test set for the difference models\n",
    "\n",
    "# predictions = xgb_predictor.predict predict(test_data.values, xgb_predictor)\n",
    "predictions = predict(test_data.values, xgb_predictor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many ways to compare the performance of a machine learning model, but let's start by simply by comparing actual to predicted values.  In this case, we're simply predicting whether the customer was a no-show (`1`) or not (`0`), which produces a simple confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(index=test_data.iloc[:, 1], columns=np.round(predictions), rownames=['actual'], colnames=['predictions'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An important point here is that because of the `np.round()` function above we are using a simple threshold (or cutoff) of 0.5.  Our predictions from `xgboost` come out as continuous values between 0 and 1 and we force them into the binary classes that we began with.  However, because a customer that is predicted to be in attendence but is in reality a \"no-show\" (FP) is expected to have the highest cost, we should consider adjusting this cutoff.  That will almost certainly increase the number of false negatives, but it can also be expected to increase the number of true positives and reduce the number of false negatives.\n",
    "\n",
    "To get a rough intuition here, let's look at the continuous values of our predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(predictions)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that changing the cutoff from 0.5 to 0.3 results in 1 more true positives, 3 more false positives, and 1 fewer false negatives.  The numbers are small overall here, but that's 6-10% of customers overall that are shifting because of a change to the cutoff.  Was this the right decision?  We may end up retaining 3 extra customers, but we also unnecessarily incentivized 5 more customers who would have stayed.  Determining optimal cutoffs is a key step in properly applying machine learning in a real-world setting.  Let's discuss this more broadly and then apply a specific, hypothetical solution for our current problem.\n",
    "\n",
    "### Relative cost of errors\n",
    "\n",
    "Any practical binary classification problem is likely to produce a similarly sensitive cutoff. That by itself isn’t a problem. After all, if the scores for two classes are really easy to separate, the problem probably isn’t very hard to begin with and might even be solvable with simple rules instead of ML.\n",
    "\n",
    "More important, if I put an ML model into production, there are costs associated with the model erroneously assigning false positives and false negatives. I also need to look at similar costs associated with correct predictions of true positives and true negatives.  Because the choice of the cutoff affects all four of these statistics, I need to consider the relative costs to the business for each of these four outcomes for each prediction.\n",
    "\n",
    "#### Assigning costs\n",
    "\n",
    "\n",
    "- Positive class -- \"No-Show  \" Patient \n",
    "- Negative class -- \"Attending\" Patient\n",
    "\n",
    "\n",
    "  \n",
    "  \n",
    "What are the costs for our problem of \"No-show\" patients? The costs, of course, depend on the specific actions that the business takes. Let's make some assumptions here.\n",
    "\n",
    "### TN\n",
    "\n",
    "- Reality        : \"Attending\" Patient\n",
    "- Model Predicts : \"Attending\" Patient\n",
    "- Cost:\\$0 \n",
    "\n",
    "### FN\n",
    "\n",
    "- Reality        : \"Attending\" Patient\n",
    "- Model Predicts : \"No-Show  \" Patient \n",
    "- Cost:\\$100\n",
    "\n",
    "### FP\n",
    "\n",
    "- Reality        : \"No-Show  \" Patient \n",
    "- Model Predicts : \"Attending\" Patient\n",
    "- Cost:\\$500\n",
    "\n",
    "### TP\n",
    "\n",
    "- Reality        : \"No-Show  \" Patient \n",
    "- Model Predicts : \"No-Show  \" Patient \n",
    "- Cost:\\$0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoffs = (np.arange(0.01, 0.70, 0.01))\n",
    "\n",
    "costs = []\n",
    "for c in cutoffs:\n",
    "    # TN / FN // FP / TP\n",
    "    costs.append(np.sum(np.sum(np.array([[0, 100], [500, 0]]) * \n",
    "                               pd.crosstab(index=test_data.iloc[:, 1].values, columns=np.where(predictions > c, 1, 0)))))\n",
    "                                        \n",
    "costs = np.array(costs)\n",
    "plt.plot(cutoffs, costs)\n",
    "plt.show()\n",
    "print('Cost is minimized near a cutoff of:', cutoffs[np.argmin(costs)], 'for a cost of : $', np.min(costs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above chart shows how picking a threshold too low results in costs skyrocketing.  Meanwhile, setting the threshold too high results in the model classifying all customers as \"No-shows\", which ultimately grows to be nearly as costly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(index=test_data.iloc[:, 1], columns=np.where(predictions >= 0.01, 1, 0), rownames=['actual'], colnames=['predictions'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (Optional) Clean-up\n",
    "\n",
    "If you're ready to be done with this notebook, please run the cell below.  This will remove the hosted endpoint you created and avoid any charges from a stray instance being left on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sagemaker.Session().delete_endpoint(xgb_predictor.endpoint)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "notice": "Copyright 2017 Amazon.com, Inc. or its affiliates. All Rights Reserved.  Licensed under the Apache License, Version 2.0 (the \"License\"). You may not use this file except in compliance with the License. A copy of the License is located at http://aws.amazon.com/apache2.0/ or in the \"license\" file accompanying this file. This file is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License."
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
